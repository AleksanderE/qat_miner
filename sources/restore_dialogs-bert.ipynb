{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v1_train_v1_test_v1_clickhouse_ru_repeat'\n",
    "description = 'Without delimeters. Train is unbalanced.'\n",
    "\n",
    "dataset_name = 'clickhouse_ru.labelled.combined'\n",
    "# dataset_name = 'ru_python_2018-2019.labelled.combined'\n",
    "# dataset_name = 'kinota1k.labelled.combined'\n",
    "\n",
    "original_dataset_dir = './datasets/'\n",
    "\n",
    "BASE_PATH = './models/bertForSeqClassification/' + version + '/'\n",
    "\n",
    "model_path = BASE_PATH + 'model/'\n",
    "# dataset_path = BASE_PATH + 'dataset/'\n",
    "dataset_path = original_dataset_dir\n",
    "cross_validation_path = BASE_PATH + 'cross_validation/'\n",
    "\n",
    "train_directory = \"\"\n",
    "test_directory = \"\"\n",
    "train_file_name = f\"{dataset_name}.restore_dialogs.bert_train_v1.csv\"\n",
    "test_file_name = f\"{dataset_name}.restore_dialogs.test.csv\"\n",
    "\n",
    "train_path = dataset_path + train_file_name\n",
    "test_path = dataset_path + test_file_name\n",
    "train_tokenized_path = train_path[:-4] + '.tokenized.csv'\n",
    "\n",
    "should_tokenize_train = True\n",
    "# should_tokenize_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir $BASE_PATH\n",
    "! mkdir $model_path\n",
    "! mkdir $dataset_path\n",
    "! mkdir $cross_validation_path\n",
    "! cp $original_dataset_dir$train_directory$train_file_name $train_path\n",
    "! cp $original_dataset_dir$test_directory$test_file_name $test_path\n",
    "! ls -lah $dataset_path\n",
    "! echo $description > $BASE_PATH\"readme.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "tqdm.tqdm_notebook().pandas()\n",
    "\n",
    "import torch\n",
    "from transformers import *\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import ast\n",
    "\n",
    "from metrics import *\n",
    "from prepare import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(df):\n",
    "    df0 = df[df['label'] == 0]\n",
    "    df1 = df[df['label'] == 1]\n",
    "    min_size = min(df0.shape[0], df1.shape[0])\n",
    "    return shuffle(pd.concat([df0.sample(min_size), df1.sample(min_size)])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if should_tokenize_train:\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    print(\"Size before balancing\", train_df.shape[0])\n",
    "    train_df =  balance(train_df)\n",
    "    print(\"Size after balancing\", train_df.shape[0])\n",
    "    \n",
    "    train_df['message1'] = train_df['message1']\\\n",
    "        .fillna('')\\\n",
    "        .apply(lambda text: text.lower())\\\n",
    "        .progress_apply(prepare_special_tokens)\n",
    "    train_df['message2'] = train_df['message2']\\\n",
    "        .fillna('')\\\n",
    "        .apply(lambda text: text.lower())\\\n",
    "        .progress_apply(prepare_special_tokens)\n",
    "    \n",
    "    if 'new_text_with_SEP_tag' not in train_df.columns:\n",
    "        train_df['new_text_with_SEP_tag'] = train_df.progress_apply(lambda row: join_sep(row['message1'], row['message2']), axis=1)\n",
    "    else:\n",
    "        train_df['new_text_with_SEP_tag'] = train_df['new_text_with_SEP_tag']\\\n",
    "            .apply(lambda text: text.lower())\\\n",
    "            .progress_apply(prepare_special_tokens)\n",
    "    train_df = shuffle(train_df)\n",
    "    verify_dataset(train_df)\n",
    "\n",
    "    print(\"Speakers:\", get_speakers_number(train_df))\n",
    "    train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_path)\n",
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'new_text_with_SEP_tag' not in test_df.columns:\n",
    "    test_df['message1'] = test_df['message1']\\\n",
    "        .fillna('')\\\n",
    "        .apply(lambda text: text.lower())\n",
    "    test_df['message2'] = test_df['message2']\\\n",
    "        .fillna('')\\\n",
    "        .apply(lambda text: text.lower())\n",
    "    test_df['new_text_with_SEP_tag'] = test_df.progress_apply(lambda row: join_sep(row['message1'], row['message2']), axis=1)\n",
    "\n",
    "\n",
    "test_df['new_text_with_SEP_tag'] = test_df['new_text_with_SEP_tag']\\\n",
    "        .apply(lambda text: text.lower())\\\n",
    "        .progress_apply(prepare_special_tokens)\n",
    "\n",
    "\n",
    "print('Speakers', get_speakers_number(test_df))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_basic_tokenize=False)\n",
    "\n",
    "assert(len(tokenizer.encode('[unused98]')) == 3)\n",
    "assert(len(tokenizer.encode('[unused99]')) == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.head(10)\n",
    "# [['new_text_with_SEP_tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.encode('[JOIN]')\n",
    "# tokenizer.encode('[join]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_tokenize_train:\n",
    "    train_df['tokenized_text'] = train_df['new_text_with_SEP_tag'].progress_apply(tokenizer.encode)\n",
    "    train_df.to_csv(train_tokenized_path, index=False)\n",
    "else:\n",
    "    train_df = pd.read_csv(train_tokenized_path)\n",
    "    train_df['tokenized_text'] = train_df['tokenized_text'].progress_apply(lambda x: ast.literal_eval(x))\n",
    "    train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сколько пар сообщений по длине оказались меньше\n",
    "(train_df['tokenized_text'].apply(len) <= 512).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество позитивов и негативов в тренировочном сете\n",
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['tokenized_text'] = test_df['new_text_with_SEP_tag'].progress_apply(tokenizer.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество позитивов и негативов в тренировочном сете\n",
    "test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['new_text_with_SEP_tag', 'tokenized_text']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['new_text_with_SEP_tag', 'tokenized_text']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(list(test_df['new_text_with_SEP_tag'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(test_df['new_text_with_SEP_tag'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = tokenizer.encode(list(test_df['new_text_with_SEP_tag'])[0].lower())\n",
    "\n",
    "[tokenizer.convert_ids_to_tokens(x) for x in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df_test):\n",
    "    df_test['pred_label'] = 0\n",
    "    _dict = {\n",
    "        'border_of_prob': [],\n",
    "        'recall': [],\n",
    "        'precision': [],\n",
    "        'f1': [],\n",
    "        'accuracy': [],\n",
    "        'percents_of_positive_preds': []\n",
    "    }\n",
    "    for i in range(1, 100):\n",
    "        try:\n",
    "            b = 0.01*i\n",
    "            df_test.loc[df_test.probs > b, 'pred_label'] = 1\n",
    "\n",
    "            num_tp = df_test[(df_test.label == df_test.pred_label) & (df_test.label == 1)].shape[0]\n",
    "            num_pos = df_test[df_test.label == 1].shape[0]\n",
    "            num_pred_pos = df_test[df_test.pred_label == 1].shape[0]\n",
    "\n",
    "            recall = num_tp / num_pos\n",
    "            precision = num_tp / num_pred_pos\n",
    "            accuracy = df_test[(df_test.label == df_test.pred_label) ].shape[0]/df_test.shape[0]\n",
    "\n",
    "            f1 = 2*recall*precision/(precision + recall)\n",
    "\n",
    "            _dict['border_of_prob'].append(b)\n",
    "            _dict['recall'].append(recall)\n",
    "            _dict['precision'].append(precision)\n",
    "            _dict['f1'].append(f1)\n",
    "            _dict['accuracy'].append(accuracy)\n",
    "            _dict['percents_of_positive_preds'].append(df_test.pred_label.value_counts()[1]/df_test.shape[0])\n",
    "            df_test['pred_label'] = 0\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    df = pd.DataFrame(_dict)\n",
    "    df.index = df['border_of_prob']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, df, batch_size):\n",
    "    df['probs'] = 0\n",
    "    with torch.no_grad():\n",
    "        # Adding SoftMax for correct interpretation\n",
    "        sm = torch.nn.Softmax(dim=1)\n",
    "        model.eval()\n",
    "        n_batches = df.shape[0] // batch_size\n",
    "        for i in tqdm.notebook.tqdm(range(n_batches)):\n",
    "            batch_df = df.iloc[i * batch_size: (i + 1) * batch_size]\n",
    "            input_ids = batch_df['tokenized_text'].tolist()\n",
    "            max_length = 512\n",
    "            input_ids = np.array([row + [0] * (max_length - len(row)) if len(row) < max_length \n",
    "                                  else row[len(row) - max_length:] \n",
    "                                  for row in input_ids])\n",
    "            input_ids = torch.tensor(input_ids).cuda()\n",
    "            outputs = model(input_ids)\n",
    "            df.loc[batch_df.index ,'probs'] = sm(outputs[0].cpu())[:, 1].numpy()\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_train(model, train_df, val_df, directory, batch_size=80):\n",
    "    n_epochs = 2\n",
    "    n_batches = train_df.shape[0] // batch_size\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    loss_list = []\n",
    "\n",
    "    save_best_model = True\n",
    "    test_every_N_steps = 200\n",
    "    max_length = 512\n",
    "    max_f1_list = []\n",
    "\n",
    "    for _ in range(n_epochs):\n",
    "        for i in tqdm.notebook.tqdm(range(n_batches)):\n",
    "            optimizer.zero_grad()\n",
    "            batch = train_df.iloc[i * batch_size: (i + 1) * batch_size]\n",
    "            input_ids = batch['tokenized_text'].tolist()\n",
    "            input_ids = np.array([row + [0] * (max_length - len(row)) if len(row) < max_length \n",
    "                                  else row[len(row) - max_length:] \n",
    "                                  for row in input_ids])\n",
    "            input_ids = torch.tensor(input_ids).cuda()\n",
    "\n",
    "            outputs = model(input_ids)\n",
    "            labels = torch.tensor(batch['label'].tolist()).cuda()\n",
    "            losses = loss(outputs[0], labels)\n",
    "            loss_list.append(losses.item())\n",
    "\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Validation and saving            \n",
    "            if i % test_every_N_steps == 0:\n",
    "                val_df = make_prediction(model, val_df, batch_size)\n",
    "                metrics = get_metrics(val_df)\n",
    "                print(metrics.f1.max())\n",
    "                if not max_f1_list or max(max_f1_list) < metrics.f1.max():\n",
    "                    torch.save(model.state_dict(), directory + \"model.pt\")\n",
    "                    print('Saved')\n",
    "                max_f1_list.append(metrics.f1.max())\n",
    "    if len(max_f1_list) == 0:\n",
    "        torch.save(model.state_dict(), directory + \"model.pt\")\n",
    "        print('Saved')\n",
    "    return loss_list, max_f1_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES_NUMBER = len(os.environ[\"CUDA_VISIBLE_DEVICES\"].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict(global_train_df, global_test_df, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    splits = skf.split(global_train_df, global_train_df['label'])\n",
    "    for index, (train_index, test_index) in enumerate(splits):\n",
    "        print('---------------- SPLIT ' + str(index + 1) + ' ----------------')\n",
    "        directory = cross_validation_path + str(index + 1) + '/'\n",
    "        create_directory_if_not_exist(directory)\n",
    "\n",
    "        train_df = global_train_df.iloc[train_index]\n",
    "        train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "        \n",
    "        train_df.to_csv(directory + 'train.csv', index=False)\n",
    "        val_df.to_csv(directory + 'val.csv', index=False)\n",
    "        test_df = global_train_df.iloc[test_index]\n",
    "        test_df.to_csv(directory + 'test.csv', index=False)\n",
    "        print('Train shape:', train_df.shape, \n",
    "              'Val shape:', val_df.shape,\n",
    "              'Test shape:', test_df.shape)\n",
    "\n",
    "        model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-uncased')\n",
    "        model.to('cuda')\n",
    "        model = torch.nn.DataParallel(model, device_ids=list(range(DEVICES_NUMBER)))\n",
    "\n",
    "        loss_list, max_f1_list = make_train(model, train_df, val_df, directory, batch_size=30)\n",
    "#         plt.plot(loss_list)\n",
    "#         plt.plot(max_f1_list)\n",
    "        \n",
    "        model.load_state_dict(torch.load(directory + \"model.pt\"))\n",
    "\n",
    "        val_df = make_prediction(model, val_df, batch_size=128)\n",
    "        val_df = calculate_maxprobs(val_df)\n",
    "        val_df.to_csv(directory + 'val.probs.csv', index=False)\n",
    "\n",
    "        test_df = make_prediction(model, test_df, batch_size=128)\n",
    "        test_df = calculate_maxprobs(test_df)\n",
    "        test_df.to_csv(directory + 'test.probs.csv', index=False)\n",
    "\n",
    "        global_test_df = make_prediction(model, global_test_df, batch_size=128)\n",
    "        global_test_df = calculate_maxprobs(global_test_df)\n",
    "        global_test_df.to_csv(directory + 'global_test.probs.csv', index=False)\n",
    "        \n",
    "        del model\n",
    "        \n",
    "        calculate_all_cv_metrics(directory, val_df, test_df, global_test_df)\n",
    "        \n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['label'].value_counts()\n",
    "test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_val_predict(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = averaged_metrics_cv(cross_validation_path, 'test.metrics_by_all.unbalanced')\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "_ = averaged_metrics_cv(cross_validation_path, 'global_test.metrics_by_all.unbalanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = averaged_metrics_cv(cross_validation_path, 'test.metrics_by_all.balanced')\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "_ = averaged_metrics_cv(cross_validation_path, 'global_test.metrics_by_all.balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = averaged_metrics_cv(cross_validation_path, 'test.metrics_by_max.unbalanced')\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "_ = averaged_metrics_cv(cross_validation_path, 'global_test.metrics_by_max.unbalanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = averaged_metrics_cv(cross_validation_path, 'test.metrics_by_max.balanced')\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "_ = averaged_metrics_cv(cross_validation_path, 'global_test.metrics_by_max.balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
