{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "from find_questions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_dataset(directory + 'clickhouse_ru.labelled.combined.csv')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogs_numbers = set(data[data['is_root'] == 1]['dialog_number'])\n",
    "data = data[data['dialog_number'].isin(dialogs_numbers)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-tulsa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "regional-logging",
   "metadata": {},
   "source": [
    "Define which messages should label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_should_predict(df):\n",
    "    labels = set(df[df['is_root'] == 1]['dialog_number'])\n",
    "    print('labels', len(labels))\n",
    "\n",
    "    df_labeled = df[(df['dialog_number'].isin(labels))]\n",
    "    print('Nodes in dialogs', df_labeled.shape[0])\n",
    "\n",
    "    df_to_predict = df_labeled[((df_labeled['is_root'] == 0) & (df_labeled['reply_to_msg_id'].isnull()))]\n",
    "    print('Nodes in predict', df_to_predict.shape[0])\n",
    "\n",
    "    df['should_predict'] = 0\n",
    "    df.loc[df['id'].isin(df_to_predict['id']), 'should_predict'] = 1\n",
    "    \n",
    "    \n",
    "set_should_predict(data)\n",
    "data['should_predict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-easter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-maine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "selective-actor",
   "metadata": {},
   "source": [
    "Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReplyTree import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = data\n",
    "\n",
    "msg_id_to_from_id_dict = {row['id']:row['from_id'] for _, row in original.iterrows()}\n",
    "msg_id_to_date_dict = {row['id']: row['date_'] for _, row in original.iterrows()}\n",
    "msg_id_to_dialog_number_dict = {row['id']:row['dialog_number'] for _, row in original.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_from_ids(msg_ids, msg_id_to_from_id_dict):\n",
    "    return set(msg_id_to_from_id_dict[id_] for id_ in msg_ids)\n",
    "\n",
    "\n",
    "def add_min_date(msg_ids, msg_id_to_date_dict):\n",
    "    return min(msg_id_to_date_dict[id_] for id_ in msg_ids)\n",
    "\n",
    "\n",
    "def add_max_date(msg_ids, msg_id_to_date_dict):\n",
    "    return max(msg_id_to_date_dict[id_] for id_ in msg_ids)\n",
    "\n",
    "\n",
    "def add_dialog_number_label(msg_ids1, msg_ids2, msg_id_to_dialog_number_dict):\n",
    "    return int(msg_id_to_dialog_number_dict[msg_ids1[0]] == msg_id_to_dialog_number_dict[msg_ids2[0]])\n",
    "\n",
    "\n",
    "def count_msgs_between(msg_ids1, msg_ids2):\n",
    "    ids1 = list(int(id_) for id1 in msg_ids1 for id_ in id1.split('__'))\n",
    "    ids2 = list(int(id_) for id2 in msg_ids2 for id_ in id2.split('__'))\n",
    "    res = 99999\n",
    "    for id1 in ids1:\n",
    "        for id2 in ids2:\n",
    "#             assert id2 > id1\n",
    "            if res > abs(id2 - id1):\n",
    "                res = abs(id2 - id1)\n",
    "    return res\n",
    "\n",
    "\n",
    "def count_seconds_between(msg_ids1, msg_ids2, msg_id_to_date_dict):\n",
    "#     ids1 = list(int(id_) for id1 in msg_ids1 for id_ in id1.split('__'))\n",
    "#     ids2 = list(int(id_) for id2 in msg_ids2 for id_ in id2.split('__'))\n",
    "#     ids1 = [int(id_) for id_ in msg_ids1]\n",
    "#     ids2 = [int(id_) for id_ in msg_ids2]\n",
    "    res = 999999999999999\n",
    "    for id1 in msg_ids1:\n",
    "        for id2 in msg_ids2:\n",
    "#             assert id2 > id1\n",
    "            time_span = abs(msg_id_to_date_dict[id2] - msg_id_to_date_dict[id1]).total_seconds()\n",
    "            if res > time_span:\n",
    "                res = time_span\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = split_into_discussion_trees(data)\n",
    "print(\"Dialogs count:\", len(dt.trees))\n",
    "# dt.filter_trees_with_len_1()\n",
    "# print(\"Dialogs with len > 1 number:\", len(dt.trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree in dt.trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'msg_ids1': [],\n",
    "       'msg_ids2': []}\n",
    "\n",
    "\n",
    "def get_nodes(tree):\n",
    "    return [id_ for id_ in tree.nodes]\n",
    "\n",
    "\n",
    "for i, first_tree in enumerate(dt.trees):\n",
    "#     print(tree)\n",
    "    for second_tree in dt.trees[:i]:\n",
    "        res['msg_ids2'].append(get_nodes(first_tree))\n",
    "        res['msg_ids1'].append(get_nodes(second_tree))\n",
    "#         print(tree)\n",
    "\n",
    "res = pd.DataFrame.from_dict(res)\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['from_ids1'] = res['msg_ids1'].apply(lambda msg_ids: add_from_ids(msg_ids, msg_id_to_from_id_dict))\n",
    "res['from_ids2'] = res['msg_ids2'].apply(lambda msg_ids: add_from_ids(msg_ids, msg_id_to_from_id_dict))\n",
    "\n",
    "res['min_date1'] = res['msg_ids1'].apply(lambda msg_ids: add_min_date(msg_ids, msg_id_to_date_dict))\n",
    "res['min_date2'] = res['msg_ids2'].apply(lambda msg_ids: add_min_date(msg_ids, msg_id_to_date_dict))\n",
    "\n",
    "res['max_date1'] = res['msg_ids1'].apply(lambda msg_ids: add_max_date(msg_ids, msg_id_to_date_dict))\n",
    "res['max_date2'] = res['msg_ids2'].apply(lambda msg_ids: add_max_date(msg_ids, msg_id_to_date_dict))\n",
    "\n",
    "\n",
    "res['msgs_between'] = res.apply(\n",
    "    lambda row: count_msgs_between(row['msg_ids1'], row['msg_ids2']), axis=1)\n",
    "\n",
    "\n",
    "res['seconds_between'] = res.apply(\n",
    "    lambda row: count_seconds_between(row['msg_ids1'], row['msg_ids2'], msg_id_to_date_dict), \n",
    "    axis=1)\n",
    "\n",
    "\n",
    "res['equal_dialog_number'] = res.apply(\n",
    "    lambda row: add_dialog_number_label(row['msg_ids1'], row['msg_ids2'], msg_id_to_dialog_number_dict), \n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['label'] = res['equal_dialog_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-session",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-street",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_data = [\n",
    "    go.Histogram(\n",
    "        x=res['msgs_between'],\n",
    "        name='',\n",
    "        opacity=0.9\n",
    "    )]\n",
    "\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(title='<b></b>', title_font=dict(size=18)),\n",
    "    xaxis=dict(title='<b></b>', title_font=dict(size=18)),\n",
    "    title={'text': '<b></b>',\n",
    "           'xanchor': 'left',\n",
    "           'pad': {'l': 240},\n",
    "           'font': {'size': 18}},\n",
    "    bargap=0.01)\n",
    "\n",
    "fig = go.Figure(data=plotly_data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res[res['msgs_between'] > 0]\n",
    "len(res[res['msgs_between'] <= 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(df):\n",
    "    df0 = df[df['label'] == 0]\n",
    "    df1 = df[df['label'] == 1]\n",
    "    min_size = min(df0.shape[0], df1.shape[0])\n",
    "    return shuffle(pd.concat([df0.sample(min_size), df1.sample(min_size)])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = res.reset_index()\n",
    "# df = res[res['msgs_between'] <= 10].reset_index()\n",
    "df = balance(df)\n",
    "\n",
    "df['equal_dialog_number'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-encounter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['equal_dialog_number'] == 1]['msgs_between'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['equal_dialog_number'] == 0]['msgs_between'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-bunny",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-playback",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fields(df, version):\n",
    "    # 2\n",
    "    df['msg_ids1_number'] = df['msg_ids1'].apply(lambda msg_ids1: len(msg_ids1))\n",
    "    # 3\n",
    "    df['msg_ids2_number'] = df['msg_ids2'].apply(lambda msg_ids2: len(msg_ids2))\n",
    "    # 4\n",
    "#     df['messages_number_between'] = df.apply(\n",
    "#         lambda row: calculate_msgs_number_between(row['msg_ids1'], row['msg_ids2'], version), axis=1\n",
    "#     )\n",
    "    df['messages_number_between'] = df.apply(\n",
    "        lambda row: count_msgs_between(row['msg_ids1'], row['msg_ids2']), axis=1\n",
    "    )\n",
    "    # 5\n",
    "    df['from_ids1_number'] = df['from_ids1'].apply(len)\n",
    "    # 6\n",
    "    df['from_ids2_number'] = df['from_ids2'].apply(len)\n",
    "    # 7\n",
    "    df['from_ids_intersection_number'] = df.apply(\n",
    "        lambda row: len(set(row['from_ids1']).intersection(set(row['from_ids2']))), axis=1)\n",
    "    # 8\n",
    "    df['len_in_seconds1'] = df.apply(\n",
    "        lambda row: (row['max_date1'] - row['min_date1']).total_seconds(), axis=1)\n",
    "    # 9\n",
    "    df['len_in_seconds2'] = df.apply(\n",
    "        lambda row: (row['max_date2'] - row['min_date2']).total_seconds(), axis=1)\n",
    "#     # 10\n",
    "#     df['distance_in_seconds'] = df.apply(\n",
    "#         lambda row: calculate_min_distance_in_seconds(\n",
    "#             row['min_date1'], row['max_date1'], row['min_date2'], row['max_date2']), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-accounting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "add_fields(df, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names = ['messages_number_between',\n",
    "                  'seconds_between', 'msg_ids1_number',\n",
    "                  'msg_ids2_number', 'from_ids1_number', 'from_ids2_number',\n",
    "                  'from_ids_intersection_number', 'len_in_seconds1', 'len_in_seconds2',\n",
    "#                   'bert_p'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['equal_dialog_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_fabric():\n",
    "    return xgb.XGBClassifier(n_estimators=100, \n",
    "                             subsample=0.6, colsample_bytree=0.6,\n",
    "                             objective= 'binary:logistic',\n",
    "\n",
    "                             max_depth=10,\n",
    "                             learning_rate=0.03,\n",
    "                             min_child_weight=1,\n",
    "                             \n",
    "                             n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-alcohol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import LeaveOneOut, StratifiedKFold\n",
    "\n",
    "from metrics import *\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict(df, fabric, features=features_names, kf=LeaveOneOut(), n_splits=5):\n",
    "    metrics_list = []\n",
    "    df['predict'] = 0\n",
    "    for train_idx, test_idx in tqdm(kf.split(df, df['label'])):\n",
    "        X_train, X_test = df[features].loc[train_idx], df[features].loc[test_idx]\n",
    "        assert X_train.shape[1] == len(features)\n",
    "        assert X_test.shape[1] == len(features)\n",
    "        y_train, y_test = df.loc[train_idx, 'label'],  df.loc[test_idx, 'label']\n",
    "\n",
    "        clf = fabric()\n",
    "        clf.fit(X_train, y_train)\n",
    "#         print(X_test.shape, len(test_idx))\n",
    "        df.loc[test_idx, 'predict'] = clf.predict_proba(X_test)[:, 1]\n",
    "#         print(df.loc[test_idx, 'predict'])\n",
    "#         df.loc[test_idx, 'predict'] = clf.predict(X_test)\n",
    "#     df['predict'] = df['predict'].astype(int)\n",
    "    metrics = precision_recall_fscore_support(df['label'], df['predict'].apply(round))\n",
    "    metrics_df = pd.DataFrame.from_dict({'class': [0, 1],\n",
    "                                         'precision': metrics[0],\n",
    "                                         'recall': metrics[1],\n",
    "                                         'f1': metrics[2],\n",
    "                                         'support': metrics[3]})\n",
    "    metrics_list.append(metrics_df)\n",
    "    metrics = pd.concat(metrics_list).groupby('class').mean()\n",
    "    return df['predict'].copy(), metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-carry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['predict'], metrics = cross_val_predict(df, xgb_fabric, features=features_names, kf=StratifiedKFold(5), n_splits=5)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-brooks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-flower",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-internet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "moderate-business",
   "metadata": {},
   "source": [
    "### Restore numbers of dialogs from pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predict_proba'] = df['predict']\n",
    "df['predict'] = df['predict'].apply(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['msg_ids1_0'] = df['msg_ids1'].apply(lambda msg_ids: msg_ids[0])\n",
    "df['msg_ids2_0'] = df['msg_ids2'].apply(lambda msg_ids: msg_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  df.groupby('msg_ids2_0')['predict_proba'].max()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_prediction'] = df.apply(lambda row: row['predict_proba'] if x[row['msg_ids2_0']] == row['predict_proba'] else 0, axis=1)\n",
    "df['final_prediction'] = df['final_prediction'].apply(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_prediction'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = precision_recall_fscore_support(df['label'], (df['final_prediction'] > 0.5))\n",
    "metrics_df = pd.DataFrame.from_dict({'class': [0, 1],\n",
    "                                     'precision': metrics[0],\n",
    "                                     'recall': metrics[1],\n",
    "                                     'f1': metrics[2],\n",
    "                                     'support': metrics[3]})\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-african",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-growth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_predicted_dialogs(df):\n",
    "    predicted_dialogs = {}\n",
    "    known_df = df[df['is_root'] == 1]\n",
    "    for tuple_ in known_df.itertuples():\n",
    "        predicted_dialogs[tuple_.id] = tuple_.dialog_number\n",
    "    return predicted_dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-donor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_labels = init_predicted_dialogs(original)\n",
    "initial_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_set_index(sets, id_):\n",
    "    for i, set_ in enumerate(sets):\n",
    "        if id_ in set_:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "\n",
    "def join_sets(sets, first_index, second_index):\n",
    "    if first_index == second_index:\n",
    "        return\n",
    "        \n",
    "    for id_ in sets[second_index]:\n",
    "        sets[first_index].add(id_)\n",
    "    sets[second_index] = set()\n",
    "\n",
    "\n",
    "def join(df):\n",
    "    sets = [set(msg_ids) for msg_ids in list(df['msg_ids1']) + list(df['msg_ids2'])]\n",
    "    sets = set([str(set_) for set_ in sets])\n",
    "    sets = [eval(set_) for set_ in sets]\n",
    "    \n",
    "    print(\"initial sets\", len(sets), sets)\n",
    "    for tuple_ in df.itertuples():\n",
    "        if tuple_.final_prediction == 1:\n",
    "            first_index = find_set_index(sets, tuple_.msg_ids1[0])\n",
    "            second_index = find_set_index(sets, tuple_.msg_ids2[0])\n",
    "            join_sets(sets, first_index, second_index)\n",
    "    return [set_ for set_ in sets if len(set_) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-asian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = join(df)\n",
    "len(sets), sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['msg_ids1_0'] == '3123'][['msg_ids1', 'msg_ids2', 'msgs_between', 'predict_proba', 'predict', 'final_prediction', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['msg_ids2_0'] == '3123'][['msg_ids1', 'msg_ids2', 'msgs_between', 'predict_proba', 'predict', 'final_prediction', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-delivery",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sets"
   ]
  },
  {
   "cell_type": "raw",
   "id": "spoken-pursuit",
   "metadata": {},
   "source": [
    " {'14987__14988__14989__14990__14991', '14992__14993'},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-third",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-dominant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_label(set_, initial_labels):\n",
    "    res = None\n",
    "    for id_, label in initial_labels.items():\n",
    "        if id_ in set_:\n",
    "            if res is None:\n",
    "                res = label\n",
    "            else:\n",
    "                return -1\n",
    "    return res if res is not None else -1\n",
    "\n",
    "\n",
    "def label_sets(sets, initial_labels):\n",
    "    res = defaultdict(list)\n",
    "    for set_ in sets:\n",
    "        label = define_label(set_, initial_labels)\n",
    "        res[label] += list(set_)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels = label_sets(sets, initial_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels[135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label(id_, final_labels):\n",
    "    for label, ids in final_labels.items():\n",
    "        if id_ in ids:\n",
    "            return label\n",
    "    return -1\n",
    "\n",
    "original['predicted_dialog_number'] = original['id'].apply(lambda id_: find_label(id_, final_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "original[original['dialog_number'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "should_predict_df = original[(original['should_predict'] == 1)]\n",
    "true_predict_df = should_predict_df[(should_predict_df['predicted_dialog_number'] == should_predict_df['dialog_number'])]\n",
    "\n",
    "accuracy = true_predict_df.shape[0] / should_predict_df.shape[0]\n",
    "print(f'Accuracy: {accuracy}', f'{true_predict_df.shape[0]}, {should_predict_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "should_predict_df[(should_predict_df['predicted_dialog_number'] != should_predict_df['dialog_number'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-observation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"without label: \", \n",
    "      should_predict_df[should_predict_df['predicted_dialog_number'] == -1].shape[0] / should_predict_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-layer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['msg_ids2_0'] == '3112__3113']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['msg_ids1', 'msg_ids2', 'msgs_between', 'predict_proba', 'predict', 'final_prediction', 'label']].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-poster",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['label'] == 1]['msgs_between'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['label'] == 0]['msgs_between'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-chamber",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-yellow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-technician",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-temple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-provincial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-somalia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-notebook",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
